---
title: "Exploring reconvictions in Scotland with Das Gupta"
author: Josiah King & Ben Matthews
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Exploring reconvictions in Scotland with Das Gupta}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, echo=FALSE,message=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
require(kableExtra)
```


Standardization and decomposition are widely used analytic techniques to adjust for the impact of compositional factors on rates.  

* _Standardization_: Shows us what a rate would have been under different scenarios - for example, if there was no change in the age/sex structure of the population, or if there was no change in the prevalence of the event we are studying (e.g. reconviction).  

* _Decomposition_: Gives us the percentage of the difference in rates between two years attributable to each of the factors we have included in the standardization.  

The _DasGuptR_ package provides an implementation of Prithwith Das Gupta's specification of these two techniques[^7].  

[^7]: As set out in his 1993 book _[Standardization and decomposition of rates: A user's manual](https://babel.hathitrust.org/cgi/pt?id=osu.32437011198450)_.   

# Reconviction rates

Scottish Government publish an annual statistical bulletin on the [Reconviction Rates in Scotland](https://www.gov.scot/publications/reconviction-rates-scotland-2016-17-offender-cohort/). 
For the cohort of people convicted in a given year, it provides information on the numbers of reconvictions they have received. 
The headline figure in this bulletin is the _reconviction rate_, which is simply the percentage of offenders who have been reconvicted within the follow-up of one year. The bulletin published in 2019 showed that Scotland's reconviction rate has fallen steadily over the last fifteen years. 

Rates such as this measure the prevalence of some event (i.e., prevalence of reconviction), but often also reflect underlying changes in, for example, the age/sex structure of the population. 
For example, if women over 40, who have a low average reconviction rate, made up a larger proportion of all people convicted then the overall reconviction rate would go down, even if the reconviction rate itself did not change for any age group.

Similarly, Scottish Government's old measure of the _average number of reconvictions per offender_ [(previously a National Indicator)](https://www2.gov.scot/About/Performance/scotPerforms/indicator/reconviction) might reflect changes in:  
  
  
* the proportion of offenders who are reconvicted  
* the frequency with which reconvicted offenders are reconvicted  
* the age-sex structure of the convicted population  
  
  

## Reconviction data

DasGuptR package provides data on the reconviction rates in Scotland between 2004 and 2016, by age group and sex. 

```{r packages}
library(tidyverse)
library(DasGuptR)
data(reconv)
str(reconv)
```

# Rate as a product/function of factors

Our starting point is our crude rate. 
In the example provided here, our _overall reconviction rate_ is simply the average of the reconviction rates for each age-sex group, _weighted by the size of the group_. 

### rate of reconviction  

We can write the _reconviction rate_ as is a function of 2 factors[^fs].  
The overall reconviction rate can be written as  
  
$\Sigma(A \times B)$  
  
where  
  
* $A$ = the proportion of offenders in a given age-sex group who are reconvicted  
* $B$ = the proportion of total offenders who are in that age-sex group  
  
The table below (2004 reconviction rates) shows how the sex-specific reconviction rates (prop_reconvicted) multiplied by the proportion of the population that group makes up (prop_offenders) sum to the overall reconviction rate.   
```{r tablerates, echo=FALSE}
reconv %>% filter(year==2004) %>%
  group_by(Gender, convicted_population) %>% 
  summarise_at(vars(one_of(c("offenders","reconvicted","reconvictions"))),sum) %>%
  select(-reconvictions) %>%
  bind_rows(.,
            reconv %>% filter(year==2004) %>% 
              group_by(convicted_population) %>%
              summarise_at(vars(one_of(c("offenders","reconvicted","reconvictions"))),sum) %>% mutate(Gender="All") %>%
              select(-reconvictions)
  ) %>%
  mutate(
    prop_reconvicted = reconvicted/offenders,
    prop_offenders = offenders/convicted_population,
    crude_rate = prop_reconvicted*prop_offenders
  ) %>% select(Gender,offenders,reconvicted,convicted_population,prop_reconvicted, prop_offenders,crude_rate) %>%
  kable(.,digits=2) %>%
  row_spec(3, bold = T, color = "white", background = "#555555") %>%
  column_spec(7,bold=T)


```

[^fs]: As an avid R user, the reliance upon the term 'factor' here will get annoying. Sorry. Just remember it's 'factor' in the sense akin to CFA/PCA. 

```{r rateexpl, include=FALSE}
reconv %>% 
  mutate(
    prop_reconvicted = reconvicted / offenders,
    prop_totaloffenders = offenders / convicted_population
  ) %>% 
  group_by(year) %>%
  summarise(
    rate=sum(prop_reconvicted*prop_totaloffenders)
  )
```

### average number of reconvictions per offender  

Likewise, the _average number of reconvictions per offender_ in a given year can likewise be written as:  
  
$\Sigma(A \times B \times C)$  
  
where  
  
* $A$ = the frequency with which reconvicted offenders are reconvicted  
* $B$ = the proportion of offenders in a given age-sex group who are reconvicted  
* $C$ = the proportion of total offenders who are in that age-sex group  
  
Again, the sex-specific crude rates in the table below (freq_reconvicted $\times$ prop_reconvicted $\times$ prop_offenders) sum to the overall average number of reconvictions per offender. Note that this measure is more easily calculated as simply the _number of reconvictions_ / _number of offenders_, but by separating out into two factors of prevalence ( _number reconvicted_ / _number of offenders_ ) and frequency ( _number of reconvictions_ / _number reconvicted_ ) we can investigate the extent to which changes in the _average number of reconvictions per offender_ are due to a) the percentages of offenders who are reconvicted, or b) the frequency with which reconvicted offenders are reconvicted.  

```{r arpoexpl, echo=FALSE}
# reconv %>% 
#   mutate(
#     prop_reconvicted = reconvicted / offenders,
#     prop_totaloffenders = offenders / convicted_population,
#     freq_reconvicted = reconvictions / reconvicted
#   ) %>% 
#   group_by(year) %>% 
#   summarise(
#     `avg reconvs per offender` = sum(freq_reconvicted*prop_reconvicted*prop_totaloffenders)
#   )

reconv %>% filter(year==2004) %>%
  group_by(Gender, convicted_population) %>% 
  summarise_at(vars(one_of(c("offenders","reconvicted","reconvictions"))),sum) %>%
  bind_rows(.,
            reconv %>% filter(year==2004) %>% 
              group_by(convicted_population) %>%
              summarise_at(vars(one_of(c("offenders","reconvicted","reconvictions"))),sum) %>% mutate(Gender="All")
  ) %>%
  mutate(
    prop_reconvicted = reconvicted/offenders,
    prop_offenders = offenders/convicted_population,
    freq_reconvicted = reconvictions/reconvicted,
    crude_rate = prop_reconvicted*prop_offenders*freq_reconvicted
  ) %>% select(Gender,reconvicted,reconvictions,freq_reconvicted,prop_reconvicted, prop_offenders,crude_rate) %>% 
  kable(.,digits=2) %>%
  row_spec(3, bold = T, color = "white", background = "#555555") %>%
  column_spec(5,bold=T)

```

## Rates as a function F of factors  

While both of the reconviction measures above can be taken as a product of different factors, other rates can often be a specific function F of factors.  
  
A simple example:  
  
Crude rate of natural increase = $A-B$  
  
* $A$ = crude birth rate  
* $B$ = crude death rate  
  
A more complex example:  
  
Crude birth rate per 1,000 population = $[AB + C(1-B)]D$  
  
* $A$ = marital births per 1,000 married women aged 15 to 49  
* $B$ = proportion of married women among all women aged 15 to 49  
* $C$ = Nonmarital births per 1,000 unmarried women aged 15 to 49  
* $D$ = proportion of women aged 15 to 49 in the total population  
  
  
  
# The Das Gupta Method

Das Gupta's methodologies of standardisation and decomposition are explained in full in his 1993 book _[Standardization and decomposition of rates: A user's manual](https://babel.hathitrust.org/cgi/pt?id=osu.32437011198450)_

## P factors, 2 populations  

The essence of Das Gupta's method is that, given a set of P factors and 2 populations, one can calculate the rates adjusted for each combination of P-1 factors (see Das Gupta 1993, p.32, equation 3.54).  
We can interpret the P-$\alpha$ adjusted rate as 'what the crude rate would look like if only $\alpha$ had changed (all else being equal)'.  
  
  
Neatly, the crude rate can be decomposed into Das Gupta's adjusted rates such that changes in the P-$\alpha$ adjusted rate are proportional to changes in crude rates.  
For instance, if the crude rate decreases by 1.2, and the P-$\alpha$ adjusted rate decreases by .6, we can say that 50% of the change is crude rate is attributable to changes in $\alpha$[^caus].  
The change in P-$\alpha$ adjusted rate is known as a _decomposition effect_, in this case the $\alpha$ _effect_.

[^caus]: Importantly, this analysis is not causal as the different decomposition effects identified by standardization and decomposition may themselves be the products of one (or more) variables not included in the analysis (Das Gupta 1993:4).  
  
  
## P factors, N populations  
  
  
Das Gupta provides a further process for standardizing the rates and decomposition effects across N populations, which can be applied to populations at given years for analysis of time series.  
This process involves first calculating the P-1 adjusted rates and decompositions effects for all possible pairwise comparisons of populations, and then standardizing these across the N populations (see Das Gupta 1993, p.106, equations 6.11 and 6.12) to obtain a consistent set of rates and effects, such that  
  
* there is only one P-$\alpha$ adjusted rate per population (as opposed to N-1)  
* the $\alpha$ _effect_ corresponding to populations 1 and 2 and the $\alpha$ _effect_ for populations 2 and 3 now sum to the $\alpha$ _effect_ corresponding to populations 1 and 3.  

  
  
  
# The DasGuptR package  

Standardization and decomposition via Das Gupta's formulae can be achieved in R via the **DasGupt_Npop()** function.   
  
  
To begin, we firstly require some data.  
  
A column is required specifying the population (e.g., *year* in the reconv data), and a column for each of the factors we wish to include in the decomposition.  
For example, if we were interested in decomposing the _average number of reconvictions per offender_ into the prevalence and frequency of reconviction, then the following (in red) would suffice:  

```{r, echo=FALSE}
reconv %>% group_by(year) %>% 
  summarise_at(vars(one_of(c("offenders","reconvicted","reconvictions"))),sum) %>% 
  mutate(
    prevalence=round(reconvicted/offenders,3), 
    frequency=round(reconvictions/reconvicted,3)
  ) %>% select(year,prevalence,frequency,offenders,reconvicted,reconvictions) %>% 
  head %>% rbind(.,"...") %>% kable() %>%
  column_spec(1:3,bold=T,color="white",background = "#D7261E") %>%
  column_spec(4:6, color = "grey10") %>%
  add_header_above(c("Population" = 1, "Decomposition Factors" = 2, "Raw numbers" = 3),background="white",color="grey70")
```

If we are also interested in including the underlying structure of the population (e.g. age and sex sub-groups) in the decomposition, then each row should identify the sub-group via a set of id variables (i.e., age and sex), with a column specifying the proportion of the population made up by that sub-group (the *pop_str* variable below):


```{r, echo=FALSE}
reconv %>% 
  mutate(
    prevalence=round(reconvicted/offenders,3), 
    frequency=round(reconvictions/reconvicted,3),
    pop_str=round(offenders/convicted_population,3)
  ) %>% select(year,Gender,Age,prevalence,frequency,pop_str,offenders,reconvicted,reconvictions) %>% 
  head %>% rbind(.,"...") %>% kable() %>%
  column_spec(1:6,bold=T,color="white",background = "#D7261E") %>%
  column_spec(7:9, color = "grey10") %>%
  add_header_above(c("Population" = 1, "ID variables" = 2, "Decomposition factors" = 3, "Raw numbers" = 3),background="white",color="grey70")
```
  
  
   
The second thing we require is the function F by which the rate is to be calculated from the decomposition factors.  
In our two examples of the _reconviction rate_ and _average number of reconvictions per offender_, rates are simply the product of factors.   
  
* reconviction rate = prevalence $\times$ pop_str[^agg]    
* avg number reconvs per offender = prevalence $\times$ frequency $\times$ pop_str  

[^agg]: When we're disaggregating by population structure, this factor remains implicitly present with a value of 1 (thereby having no impact).

## Standardizing and decomposing Scotland's reconviction rate  
  
Below, we decompose Scotland's reconviction rate into the prevalence of reconviction and the age-sex structure of the convicted population.  
This is useful because we can then investigate how much changes in the overall reconviction rate are due to fewer people being reconvicted, or due to the changing age-sex mix of the convicted population (so, if younger people tend to have higher reconviction rates, but are becoming more frequently [diverted from prosecution](http://scottishjusticematters.com/wp-content/uploads/Shrinking-YJ-population-SJM_5-1_April2017-18.pdf), then younger groups will begin to make up a smaller proportion of the convicted population, and so the overall rate at which the population is reconvicted will go down (even if the rates at which different sub-groups are reconvicted do not).  
  
The code below decomposes the Scotland's reconviction rates for 2004 to 2007 into prevalence and population structure. We focus initially on this small period of time simply because the output becomes cumbersome as the the number of populations increases.  

```{r reconv_decomp, warning=FALSE,message=FALSE}
# create our decomposition factors
reconv <- 
  reconv %>% 
  mutate(
    prevalence = reconvicted/offenders,
    frequency = reconvictions/reconvicted, #not used here
    pop_str = offenders/convicted_population
  ) %>% 
  filter(year %in% 2004:2007) #the output is pretty cumbersome, so lets keep it at 4 years for now

#standardize and decompose!
reconv_DG <- DasGupt_Npop(df=reconv,
                          pop=year,prevalence, pop_str,
                          id_vars=c(Age,Gender),ratefunction="prevalence*pop_str")
                          # the default ratefunction calculates rate as the product of all specified factors
                          # in theory this function works with any function you like.
```
  
  
As shown below, the DasGupt_Npop() function returns a tibble with a column for the P-$\alpha$ adjusted rates in each population.  The 'factor' column specifies $\alpha$.  

It also specifies the standardized decomposition $\alpha$ effects for each pairwise comparison of populations (again, the 'factor' column specifies $\alpha$)

```{r}
str(reconv_DG)
```



